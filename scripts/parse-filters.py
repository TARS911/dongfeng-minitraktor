#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–µ—Ä —Ñ–∏–ª—å—Ç—Ä–æ–≤ —Å ZIP-AGRO.RU
"""

import requests
from bs4 import BeautifulSoup
import csv
import json
import time
from pathlib import Path

BASE_URL = "https://zip-agro.ru/filtry"

def parse_page(page_num):
    """–ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
    url = f"{BASE_URL}?page={page_num}"

    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')

        products = []
        items = soup.select('.product-item')

        print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –Ω–∞–π–¥–µ–Ω–æ {len(items)} —Ç–æ–≤–∞—Ä–æ–≤")

        for item in items:
            try:
                # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
                name_elem = item.select_one('.product-name a')
                name = name_elem.text.strip() if name_elem else "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"

                # –ê—Ä—Ç–∏–∫—É–ª
                article_elem = item.select_one('.badge.stiker-upc') or item.select_one('.badge.stiker-ean')
                article = article_elem.text.strip() if article_elem else ""

                products.append({
                    'name': name,
                    'article': article,
                    'category': '–§–∏–ª—å—Ç—Ä—ã'
                })

            except Exception as e:
                print(f"      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–≤–∞—Ä–∞: {e}")
                continue

        return products

    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
        return []

def main():
    print("\nüöÄ –ü–ê–†–°–ò–ù–ì –§–ò–õ–¨–¢–†–û–í –° ZIP-AGRO.RU")
    print("=" * 70)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü
    response = requests.get(BASE_URL, timeout=10)
    soup = BeautifulSoup(response.content, 'html.parser')

    # –ò—â–µ–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é
    pagination_text = soup.select_one('.pagination-info')
    if pagination_text:
        text = pagination_text.text
        print(f"\nüìã {text}")

    # –ü–∞—Ä—Å–∏–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    all_products = []
    page = 1

    print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤...\n")

    while True:
        products = parse_page(page)

        if not products:
            break

        all_products.extend(products)
        page += 1
        time.sleep(0.5)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏

    print(f"\n‚úÖ –í—Å–µ–≥–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {len(all_products)} —Ç–æ–≤–∞—Ä–æ–≤")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
    output_dir = Path("parsed_data")
    output_dir.mkdir(exist_ok=True)

    csv_file = output_dir / "zip-agro-filters.csv"
    json_file = output_dir / "zip-agro-filters.json"

    # CSV
    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        if all_products:
            writer = csv.DictWriter(f, fieldnames=['name', 'article', 'category'])
            writer.writeheader()
            writer.writerows(all_products)

    print(f"üíæ CSV: {csv_file}")

    # JSON
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(all_products, f, ensure_ascii=False, indent=2)

    print(f"üíæ JSON: {json_file}")
    print("\n‚úÖ –ì–æ—Ç–æ–≤–æ!\n")

if __name__ == "__main__":
    main()
