#!/usr/bin/env python3
"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä ZIP-AGRO.RU —Å –ü–û–õ–ù–´–ú–ò –¥–∞–Ω–Ω—ã–º–∏
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python3 parse-zip-agro-universal.py <URL> <output_filename>
"""

import sys
import requests
from bs4 import BeautifulSoup
import csv
import json
import time
import re
from pathlib import Path

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

def parse_page(url, page_num):
    """–ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
    if page_num == 1:
        page_url = url
    else:
        page_url = f"{url}?page={page_num}"

    try:
        response = requests.get(page_url, headers=HEADERS, timeout=30)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')

        products = []
        items = soup.select('.product-item')

        print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –Ω–∞–π–¥–µ–Ω–æ {len(items)} —Ç–æ–≤–∞—Ä–æ–≤")

        for item in items:
            try:
                # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
                name_elem = item.select_one('.product-name a')
                title = name_elem.text.strip() if name_elem else ""
                product_url = name_elem.get('href', '') if name_elem else ""
                if product_url and not product_url.startswith('http'):
                    product_url = 'https://zip-agro.ru' + product_url

                # –ê—Ä—Ç–∏–∫—É–ª
                article_elem = item.select_one('.badge.stiker-upc') or item.select_one('.badge.stiker-ean')
                article = article_elem.text.strip() if article_elem else ""

                # –¶–µ–Ω–∞
                price_elem = item.select_one('.price-new, .price')
                price = ""
                if price_elem:
                    price_text = price_elem.text.strip()
                    price_match = re.search(r'[\d\s]+\.?\d*', price_text.replace(' ', ''))
                    if price_match:
                        price = price_match.group(0).replace(' ', '')

                # –§–æ—Ç–æ (–∏–∑ data-src, —Ç.–∫. lazy loading)
                image_elem = item.select_one('img')
                image_url = ""
                if image_elem:
                    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º data-src (–¥–ª—è lazy loading)
                    image_url = image_elem.get('data-src', '') or image_elem.get('src', '')
                    # –ï—Å–ª–∏ URL –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π, –¥–µ–ª–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–º
                    if image_url and not image_url.startswith('http'):
                        image_url = 'https://zip-agro.ru/' + image_url.lstrip('/')

                # –ù–∞–ª–∏—á–∏–µ
                stock_elem = item.select_one('.stock-status, .availability')
                stock = stock_elem.text.strip() if stock_elem else "–í –Ω–∞–ª–∏—á–∏–∏"

                # –û–ø–∏—Å–∞–Ω–∏–µ (–∫—Ä–∞—Ç–∫–æ–µ)
                desc_elem = item.select_one('.product-description, .caption p')
                description = desc_elem.text.strip() if desc_elem else ""

                # –ë—Ä–µ–Ω–¥ –∏–∑ URL –∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                brand = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                if 'dongfeng' in url.lower():
                    brand = "DongFeng"
                elif 'foton' in url.lower():
                    brand = "Foton"
                elif 'jinma' in url.lower():
                    brand = "Jinma"
                elif 'xingtai' in url.lower():
                    brand = "Xingtai"

                products.append({
                    'title': title,
                    'article': article,
                    'price': price,
                    'brand': brand,
                    'category': '–ó–∞–ø—á–∞—Å—Ç–∏',
                    'stock': stock,
                    'description': description,
                    'url': product_url,
                    'image_url': image_url
                })

            except Exception as e:
                print(f"      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–≤–∞—Ä–∞: {e}")
                continue

        return products

    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
        return []

def main():
    if len(sys.argv) < 3:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python3 parse-zip-agro-universal.py <URL> <output_filename>")
        sys.exit(1)

    base_url = sys.argv[1]
    output_name = sys.argv[2]

    print(f"\nüöÄ –ü–ê–†–°–ò–ù–ì: {base_url}")
    print("=" * 70)

    # –ü–∞—Ä—Å–∏–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    all_products = []
    seen_urls = set()  # –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö URL
    page = 1

    print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤...\n")

    while True:
        products = parse_page(base_url, page)

        if not products or len(products) == 0:
            break

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã (–Ω–µ –¥—É–±–ª–∏–∫–∞—Ç—ã)
        new_products = []
        for p in products:
            if p['url'] not in seen_urls:
                seen_urls.add(p['url'])
                new_products.append(p)

        # –ï—Å–ª–∏ –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –Ω–µ—Ç - –≤—Å–µ —Ç–æ–≤–∞—Ä—ã —É–∂–µ —Å–ø–∞—Ä—Å–µ–Ω—ã
        if len(new_products) == 0:
            print(f"   ‚ö†Ô∏è  –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –≤—Å–µ —Ç–æ–≤–∞—Ä—ã —É–∂–µ —Å–ø–∞—Ä—Å–µ–Ω—ã, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è")
            break

        all_products.extend(new_products)

        # –ï—Å–ª–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –º–µ–Ω—å—à–µ —Ç–æ–≤–∞—Ä–æ–≤ —á–µ–º –æ–±—ã—á–Ω–æ - –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
        if len(new_products) < len(products):
            print(f"   ‚ÑπÔ∏è  –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: –Ω–∞–π–¥–µ–Ω–æ {len(new_products)} –Ω–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ (–ø—Ä–æ–ø—É—â–µ–Ω–æ {len(products) - len(new_products)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)")

        page += 1
        time.sleep(0.5)

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ 50 —Å—Ç—Ä–∞–Ω–∏—Ü
        if page > 50:
            print("   ‚ö†Ô∏è  –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü (50)")
            break

    print(f"\n‚úÖ –í—Å–µ–≥–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {len(all_products)} —Ç–æ–≤–∞—Ä–æ–≤")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    output_dir = Path("parsed_data/zip-agro")
    output_dir.mkdir(parents=True, exist_ok=True)

    csv_file = output_dir / f"{output_name}.csv"
    json_file = output_dir / f"{output_name}.json"

    # CSV
    fieldnames = ['title', 'article', 'price', 'brand', 'category', 'stock', 'description', 'url', 'image_url']
    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        if all_products:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(all_products)

    print(f"üíæ CSV: {csv_file}")

    # JSON
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(all_products, f, ensure_ascii=False, indent=2)

    print(f"üíæ JSON: {json_file}")
    print("‚úÖ –ì–æ—Ç–æ–≤–æ!\n")

if __name__ == "__main__":
    main()
