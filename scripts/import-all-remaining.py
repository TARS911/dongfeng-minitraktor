#!/usr/bin/env python3
"""
–ò–º–ø–æ—Ä—Ç –í–°–ï–• –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ parsed_data –≤ Supabase
–í–∫–ª—é—á–∞–µ—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –∑–∞–ø—á–∞—Å—Ç–∏, –¥–≤–∏–≥–∞—Ç–µ–ª–∏, —Ñ–∏–ª—å—Ç—Ä—ã, –Ω–∞—Å–æ—Å—ã –∏ —Ç.–¥.
"""

import json
import os
import re
import sys
from pathlib import Path

from dotenv import load_dotenv
from supabase import Client, create_client

load_dotenv("frontend/.env.local")

SUPABASE_URL = os.getenv("NEXT_PUBLIC_SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    print("‚ùå –û—à–∏–±–∫–∞: –ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è SUPABASE")
    sys.exit(1)

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

PARTS_CATEGORY_ID = 2  # ID –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ "–ó–∞–ø—á–∞—Å—Ç–∏"

# –§–∞–π–ª—ã –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Ö)
SKIP_FILES = {
    "zip-agro-foton-all.json",
    "zip-agro-jinma-all.json",
    "zip-agro-xingtai-all-sorted.json",
    "tata-agro-foton.json",
    "tata-agro-jinma.json",
    "tata-agro-xingtai.json",
    "dongfeng_tractors.json",  # –¢—Ä–∞–∫—Ç–æ—Ä—ã, –Ω–µ –∑–∞–ø—á–∞—Å—Ç–∏
}


def create_slug(name, brand="", counter=0):
    """–°–æ–∑–¥–∞—ë—Ç slug –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"""
    translit_map = {
        "–∞": "a", "–±": "b", "–≤": "v", "–≥": "g", "–¥": "d", "–µ": "e", "—ë": "yo",
        "–∂": "zh", "–∑": "z", "–∏": "i", "–π": "y", "–∫": "k", "–ª": "l", "–º": "m",
        "–Ω": "n", "–æ": "o", "–ø": "p", "—Ä": "r", "—Å": "s", "—Ç": "t", "—É": "u",
        "—Ñ": "f", "—Ö": "h", "—Ü": "ts", "—á": "ch", "—à": "sh", "—â": "sch",
        "—ä": "", "—ã": "y", "—å": "", "—ç": "e", "—é": "yu", "—è": "ya",
    }

    slug = name.lower()
    for ru, en in translit_map.items():
        slug = slug.replace(ru, en)

    slug = re.sub(r"[^\w\s-]", "", slug)
    slug = re.sub(r"[-\s]+", "-", slug)
    slug = slug.strip("-")

    if brand:
        slug = f"{brand.lower()}-{slug}"

    if counter > 0:
        slug = f"{slug}-{counter}"

    return slug[:100]


def parse_price(price_str):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–Ω—ã"""
    if not price_str:
        return 0

    cleaned = re.sub(r"[^\d.,]", "", str(price_str))
    cleaned = cleaned.replace(",", ".")

    try:
        return float(cleaned)
    except:
        return 0


def detect_brand(product):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –±—Ä–µ–Ω–¥ –∏–∑ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–∞"""
    brand = product.get("brand", "").upper()
    if brand:
        return brand

    name = product.get("title", product.get("name", "")).upper()

    if "FOTON" in name or "LOVOL" in name:
        return "FOTON"
    elif "JINMA" in name or "–î–ñ–ò–ù–ú–ê" in name:
        return "JINMA"
    elif "XINGTAI" in name or "–°–ò–ù–¢–ê–ô" in name:
        return "XINGTAI"
    elif "DONGFENG" in name or "–î–û–ù–ì–§–ï–ù–ì" in name:
        return "DONGFENG"

    return "UNIVERSAL"


def detect_part_type(product, filename):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∑–∞–ø—á–∞—Å—Ç–∏ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ –∏ —Ç–æ–≤–∞—Ä–∞"""
    filename_lower = filename.lower()
    name = product.get("title", product.get("name", "")).lower()

    # –ü–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    if "filter" in filename_lower or "—Ñ–∏–ª—å—Ç—Ä" in name:
        return "filters"
    elif "pump" in filename_lower or "–Ω–∞—Å–æ—Å" in name:
        return "pumps"
    elif "fuel" in filename_lower or "—Ç–æ–ø–ª–∏–≤" in name:
        return "fuel-system"
    elif "engine" in filename_lower or "–¥–≤–∏–≥–∞—Ç–µ–ª" in name or "–º–æ—Ç–æ—Ä" in name:
        return "engines"
    elif "kpp" in filename_lower or "–∫–æ—Ä–æ–±–∫–∞" in name or "transmission" in name:
        return "transmission"
    elif "hydraul" in filename_lower or "–≥–∏–¥—Ä–∞–≤–ª–∏–∫" in name:
        return "hydraulics"

    return "parts"


def normalize_product(product, filename, slug_counter=0):
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–æ–≤–∞—Ä–∞"""
    name = product.get("title", product.get("name", "")).strip()
    article = product.get("article", product.get("sku", ""))
    price = parse_price(product.get("price", 0))
    brand = detect_brand(product)
    part_type = detect_part_type(product, filename)
    description = product.get("description", "")
    image_url = product.get("image_url", "")
    source_url = product.get("url", product.get("link", ""))

    return {
        "name": name,
        "slug": create_slug(name, brand, slug_counter),
        "category_id": PARTS_CATEGORY_ID,
        "price": price,
        "old_price": None,
        "in_stock": price > 0,
        "image_url": image_url,
        "description": description if description else f"–ó–∞–ø—á–∞—Å—Ç—å –¥–ª—è –º–∏–Ω–∏—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤",
        "manufacturer": brand,
        "model": article if article else None,
        "specifications": {
            "article": article,
            "source_url": source_url,
            "part_type": part_type,
            "brand": product.get("brand", ""),
            "category": product.get("category", ""),
        },
    }


def find_all_json_files():
    """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ JSON —Ñ–∞–π–ª—ã –≤ parsed_data"""
    json_files = []

    for root, dirs, files in os.walk("parsed_data"):
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º archive
        if "archive" in root:
            continue

        for file in files:
            if file.endswith(".json") and file not in SKIP_FILES:
                json_files.append(os.path.join(root, file))

    return json_files


def import_all_remaining():
    """–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Å–µ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Ç–æ–≤–∞—Ä—ã"""
    print("\n" + "=" * 70)
    print("–ò–ú–ü–û–†–¢ –í–°–ï–• –û–°–¢–ê–í–®–ò–•–°–Ø –¢–û–í–ê–†–û–í –í SUPABASE")
    print("=" * 70 + "\n")

    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ JSON —Ñ–∞–π–ª—ã
    all_files = find_all_json_files()
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ JSON —Ñ–∞–π–ª–æ–≤: {len(all_files)}\n")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ç–æ–≤–∞—Ä—ã
    print("üîç –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ –ë–î...")
    existing_response = supabase.table("products").select("name").execute()
    existing_names = {p["name"].lower().strip() for p in existing_response.data}
    print(f"üìä –¢–æ–≤–∞—Ä–æ–≤ —É–∂–µ –≤ –ë–î: {len(existing_names)}\n")

    all_new_products = []
    total_from_files = 0
    slug_counter_map = {}
    files_processed = 0

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
    for file_path in all_files:
        if not os.path.exists(file_path):
            continue

        try:
            with open(file_path, "r", encoding="utf-8") as f:
                products = json.load(f)
        except:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path}")
            continue

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Ñ–∞–π–ª—ã
        if not isinstance(products, list) or len(products) == 0:
            continue

        file_name = os.path.basename(file_path)
        total_from_files += len(products)
        new_count = 0
        files_processed += 1

        for product in products:
            name = product.get("title", product.get("name", "")).strip()
            if name and name.lower() not in existing_names:
                brand = detect_brand(product)
                base_slug = create_slug(name, brand, 0)

                if base_slug in slug_counter_map:
                    slug_counter_map[base_slug] += 1
                else:
                    slug_counter_map[base_slug] = 0

                normalized = normalize_product(
                    product, file_name, slug_counter_map[base_slug]
                )
                if normalized["name"]:
                    all_new_products.append(normalized)
                    new_count += 1

        if new_count > 0:
            print(f"üì¶ {file_name}: {len(products)} —Ç–æ–≤–∞—Ä–æ–≤, –Ω–æ–≤—ã—Ö: {new_count}")

    print(f"\nüìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {files_processed}")
    print(f"üìä –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Ñ–∞–π–ª–∞—Ö: {total_from_files}")
    print(f"‚ú® –ù–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞: {len(all_new_products)}\n")

    if not all_new_products:
        print("‚úÖ –í—Å–µ —Ç–æ–≤–∞—Ä—ã —É–∂–µ –µ—Å—Ç—å –≤ –±–∞–∑–µ!")
        return

    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–æ–≤–∞—Ä—ã –ø–∞–∫–µ—Ç–∞–º–∏
    BATCH_SIZE = 100
    imported_count = 0
    error_count = 0

    for i in range(0, len(all_new_products), BATCH_SIZE):
        batch = all_new_products[i : i + BATCH_SIZE]

        try:
            response = supabase.table("products").insert(batch).execute()
            imported_count += len(batch)
            print(
                f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {imported_count}/{len(all_new_products)} —Ç–æ–≤–∞—Ä–æ–≤"
            )
        except Exception as e:
            error_count += len(batch)
            print(
                f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –ø–∞–∫–µ—Ç–∞ {i}-{i + BATCH_SIZE}: {str(e)[:100]}"
            )

    print("\n" + "=" * 70)
    print("–ò–ú–ü–û–†–¢ –ó–ê–í–ï–†–®–Å–ù!")
    print("=" * 70)
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {imported_count}")
    print(f"‚ùå –û—à–∏–±–æ–∫: {error_count}")
    print(f"üìä –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Ñ–∞–π–ª–∞—Ö: {total_from_files}")
    print(f"üìä –ë—ã–ª–æ –≤ –ë–î: {len(existing_names)}")
    print(f"üìä –°—Ç–∞–ª–æ –≤ –ë–î: {len(existing_names) + imported_count}")
    print("=" * 70 + "\n")


if __name__ == "__main__":
    import_all_remaining()
