#!/usr/bin/env python3
"""
–ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –∑–∞–ø—á–∞—Å—Ç–µ–π DongFeng 240-244 —Å ZIP-AGRO.RU
–ü–∞—Ä—Å–∏—Ç –í–°–ï –¥–∞–Ω–Ω—ã–µ: –Ω–∞–∑–≤–∞–Ω–∏–µ, –∞—Ä—Ç–∏–∫—É–ª, —Ü–µ–Ω—É, —Ñ–æ—Ç–æ, –æ–ø–∏—Å–∞–Ω–∏–µ, url
"""

import requests
from bs4 import BeautifulSoup
import csv
import json
import time
from pathlib import Path

BASE_URL = "https://zip-agro.ru/zapchasti-dongfeng-240-244"

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

def parse_page(page_num):
    """–ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
    if page_num == 1:
        url = BASE_URL
    else:
        url = f"{BASE_URL}?page={page_num}"

    try:
        response = requests.get(url, headers=HEADERS, timeout=30)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')

        products = []
        items = soup.select('.product-item')

        print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –Ω–∞–π–¥–µ–Ω–æ {len(items)} —Ç–æ–≤–∞—Ä–æ–≤")

        for item in items:
            try:
                # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
                name_elem = item.select_one('.product-name a')
                title = name_elem.text.strip() if name_elem else ""
                product_url = name_elem.get('href', '') if name_elem else ""
                if product_url and not product_url.startswith('http'):
                    product_url = 'https://zip-agro.ru' + product_url

                # –ê—Ä—Ç–∏–∫—É–ª
                article_elem = item.select_one('.badge.stiker-upc') or item.select_one('.badge.stiker-ean')
                article = article_elem.text.strip() if article_elem else ""

                # –¶–µ–Ω–∞
                price_elem = item.select_one('.price-new, .price')
                price = ""
                if price_elem:
                    price_text = price_elem.text.strip()
                    # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä –∏ —Ç–æ—á–∫–∏
                    import re
                    price_match = re.search(r'[\d\s]+\.?\d*', price_text.replace(' ', ''))
                    if price_match:
                        price = price_match.group(0).replace(' ', '')

                # –§–æ—Ç–æ (–∏–∑ data-src, —Ç.–∫. lazy loading)
                image_elem = item.select_one('img')
                image_url = ""
                if image_elem:
                    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º data-src (–¥–ª—è lazy loading)
                    image_url = image_elem.get('data-src', '') or image_elem.get('src', '')
                    # –ï—Å–ª–∏ URL –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π, –¥–µ–ª–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–º
                    if image_url and not image_url.startswith('http'):
                        image_url = 'https://zip-agro.ru/' + image_url.lstrip('/')

                # –ù–∞–ª–∏—á–∏–µ
                stock_elem = item.select_one('.stock-status, .availability')
                stock = stock_elem.text.strip() if stock_elem else "–í –Ω–∞–ª–∏—á–∏–∏"

                # –û–ø–∏—Å–∞–Ω–∏–µ (–∫—Ä–∞—Ç–∫–æ–µ)
                desc_elem = item.select_one('.product-description, .caption p')
                description = desc_elem.text.strip() if desc_elem else ""

                products.append({
                    'title': title,
                    'article': article,
                    'price': price,
                    'brand': 'DongFeng',
                    'category': '–ó–∞–ø—á–∞—Å—Ç–∏',
                    'stock': stock,
                    'description': description,
                    'url': product_url,
                    'image_url': image_url
                })

            except Exception as e:
                print(f"      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–≤–∞—Ä–∞: {e}")
                continue

        return products

    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
        return []

def main():
    print("\nüöÄ –ü–û–õ–ù–´–ô –ü–ê–†–°–ò–ù–ì –ó–ê–ü–ß–ê–°–¢–ï–ô DONGFENG 240-244 –° ZIP-AGRO.RU")
    print("=" * 70)

    # –ü–∞—Ä—Å–∏–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    all_products = []
    page = 1

    print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤...\n")

    while True:
        products = parse_page(page)

        if not products or len(products) == 0:
            break

        all_products.extend(products)
        page += 1
        time.sleep(0.5)

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ 30 —Å—Ç—Ä–∞–Ω–∏—Ü
        if page > 30:
            print("   ‚ö†Ô∏è  –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü (30)")
            break

    print(f"\n‚úÖ –í—Å–µ–≥–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {len(all_products)} —Ç–æ–≤–∞—Ä–æ–≤")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
    output_dir = Path("parsed_data/zip-agro")
    output_dir.mkdir(exist_ok=True)

    csv_file = output_dir / "zip-agro-dongfeng-240-244.csv"
    json_file = output_dir / "zip-agro-dongfeng-240-244.json"

    # CSV
    fieldnames = ['title', 'article', 'price', 'brand', 'category', 'stock', 'description', 'url', 'image_url']
    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        if all_products:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(all_products)

    print(f"üíæ CSV: {csv_file}")

    # JSON
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(all_products, f, ensure_ascii=False, indent=2)

    print(f"üíæ JSON: {json_file}")
    print("\n‚úÖ –ì–æ—Ç–æ–≤–æ!\n")

if __name__ == "__main__":
    main()
