#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –£—Ä–∞–ª–µ—Ü –∏ Xingtai –≤ –æ–¥–Ω—É —Ç–∞–±–ª–∏—Ü—É
–°–æ–∑–¥–∞—ë—Ç –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–µ JSON, CSV –∏ SQL —Ñ–∞–π–ª—ã
"""
import json
import csv
import sys
import re
from pathlib import Path

sys.stdout.reconfigure(encoding='utf-8', line_buffering=True)

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
BASE_DIR = "parsed_data/agrodom/organized"
URALETS_JSON = f"{BASE_DIR}/by-brand/–£—Ä–∞–ª–µ—Ü.json"
XINGTAI_JSON = f"{BASE_DIR}/by-brand/Xingtai.json"

OUTPUT_JSON = f"{BASE_DIR}/by-brand/–£—Ä–∞–ª–µ—Ü-Xingtai.json"
OUTPUT_CSV = f"{BASE_DIR}/csv/by-brand/–£—Ä–∞–ª–µ—Ü-Xingtai.csv"
OUTPUT_SQL = f"{BASE_DIR}/sql/–£—Ä–∞–ª–µ—Ü-Xingtai-parts.sql"

def create_slug(text):
    """–°–æ–∑–¥–∞—ë—Ç URL-friendly slug –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    text = text.lower()

    translit = {
        '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': 'g', '–¥': 'd', '–µ': 'e', '—ë': 'yo',
        '–∂': 'zh', '–∑': 'z', '–∏': 'i', '–π': 'y', '–∫': 'k', '–ª': 'l', '–º': 'm',
        '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
        '—Ñ': 'f', '—Ö': 'h', '—Ü': 'ts', '—á': 'ch', '—à': 'sh', '—â': 'sch',
        '—ä': '', '—ã': 'y', '—å': '', '—ç': 'e', '—é': 'yu', '—è': 'ya'
    }

    result = ''
    for char in text:
        result += translit.get(char, char)

    result = re.sub(r'[^a-z0-9\-\s]', '', result)
    result = re.sub(r'\s+', '-', result)
    result = re.sub(r'-+', '-', result)
    result = result.strip('-')

    return result[:100]

def extract_price(price_str):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–Ω—ã –∏–∑ —Å—Ç—Ä–æ–∫–∏"""
    if not price_str:
        return None

    price = re.sub(r'[^\d.,]', '', price_str)
    price = price.replace(',', '.')

    try:
        return float(price)
    except:
        return None

def escape_sql(text):
    """–≠–∫—Ä–∞–Ω–∏—Ä—É–µ—Ç –æ–¥–∏–Ω–∞—Ä–Ω—ã–µ –∫–∞–≤—ã—á–∫–∏ –¥–ª—è SQL"""
    if text is None:
        return 'NULL'
    return f"'{text.replace(chr(39), chr(39)+chr(39))}'"

def generate_sql_inserts(products, brand_name):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç SQL INSERT statements"""
    sql_lines = []

    sql_lines.append(f"-- –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞–ø—á–∞—Å—Ç–µ–π: {brand_name}")
    sql_lines.append(f"-- –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(products)}")
    sql_lines.append(f"-- –î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: 2025-11-18\n")

    sql_lines.append("-- –ù–∞—á–∏–Ω–∞–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é")
    sql_lines.append("BEGIN;\n")

    slugs_seen = set()
    inserted = 0

    for idx, product in enumerate(products, 1):
        name = product.get('name', '').strip()
        if not name:
            continue

        # –°–æ–∑–¥–∞—ë–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π slug
        base_slug = create_slug(name)
        slug = base_slug
        counter = 1
        while slug in slugs_seen:
            slug = f"{base_slug}-{counter}"
            counter += 1
        slugs_seen.add(slug)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        price = extract_price(product.get('price', ''))
        sku = product.get('sku', '').strip() or None
        image_url = product.get('image_url', '').strip() or None
        product_url = product.get('link', '').strip() or None

        brand = product.get('brand', brand_name)
        category = product.get('category', '–ü—Ä–æ—á–µ–µ')
        subcategory = product.get('subcategory')

        # –§–æ—Ä–º–∏—Ä—É–µ–º SQL INSERT
        values = []
        values.append(escape_sql(name))
        values.append(escape_sql(slug))
        values.append(escape_sql(sku))
        values.append('NULL')  # category_id
        values.append(escape_sql(subcategory))
        values.append(str(price) if price else 'NULL')
        values.append('NULL')  # old_price
        values.append('true')  # in_stock
        values.append("'unknown'")  # stock_status
        values.append(escape_sql(brand))
        values.append('NULL')  # compatible_models
        values.append('NULL')  # part_number
        values.append('NULL')  # description
        values.append('NULL')  # specifications
        values.append(escape_sql(image_url))
        values.append('NULL')  # images_gallery
        values.append(escape_sql(product_url))

        insert_sql = f"INSERT INTO parts (name, slug, sku, category_id, subcategory, price, old_price, in_stock, stock_status, manufacturer, compatible_models, part_number, description, specifications, image_url, images_gallery, product_url) VALUES ({', '.join(values)}); -- {category}"
        sql_lines.append(insert_sql)

        inserted += 1

        if idx % 100 == 0:
            sql_lines.append(f"\n-- –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {idx}/{len(products)}\n")

    sql_lines.append("\n-- –ó–∞–≤–µ—Ä—à–∞–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é")
    sql_lines.append("COMMIT;\n")

    sql_lines.append(f"-- –£—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {inserted}")

    return '\n'.join(sql_lines), inserted

def main():
    print("\n" + "="*70)
    print("–û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –î–ê–ù–ù–´–•: –£–†–ê–õ–ï–¶ + XINGTAI")
    print("="*70 + "\n")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    print("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    with open(URALETS_JSON, 'r', encoding='utf-8') as f:
        uralets_data = json.load(f)
    print(f"  ‚úì –£—Ä–∞–ª–µ—Ü: {len(uralets_data)} —Ç–æ–≤–∞—Ä–æ–≤")

    with open(XINGTAI_JSON, 'r', encoding='utf-8') as f:
        xingtai_data = json.load(f)
    print(f"  ‚úì Xingtai: {len(xingtai_data)} —Ç–æ–≤–∞—Ä–æ–≤")

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
    merged_data = uralets_data + xingtai_data
    total = len(merged_data)
    print(f"\n‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ: {total} —Ç–æ–≤–∞—Ä–æ–≤\n")

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∏ –Ω–∞–∑–≤–∞–Ω–∏—é
    merged_data.sort(key=lambda x: (x.get('category', ''), x.get('name', '')))

    # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON
    print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON...")
    with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
        json.dump(merged_data, f, ensure_ascii=False, indent=2)
    file_size = Path(OUTPUT_JSON).stat().st_size / 1024
    print(f"  ‚úì {OUTPUT_JSON}")
    print(f"  ‚úì –†–∞–∑–º–µ—Ä: {file_size:.1f} KB\n")

    # 2. –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º CSV
    print("üìä –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV...")
    fieldnames = ['name', 'price', 'brand', 'category', 'subcategory', 'sku', 'image_url', 'link']
    with open(OUTPUT_CSV, 'w', encoding='utf-8', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
        writer.writeheader()
        writer.writerows(merged_data)
    file_size = Path(OUTPUT_CSV).stat().st_size / 1024
    print(f"  ‚úì {OUTPUT_CSV}")
    print(f"  ‚úì –†–∞–∑–º–µ—Ä: {file_size:.1f} KB\n")

    # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º SQL
    print("üóÑÔ∏è –ì–µ–Ω–µ—Ä–∞—Ü–∏—è SQL...")
    Path(OUTPUT_SQL).parent.mkdir(parents=True, exist_ok=True)
    sql_content, inserted = generate_sql_inserts(merged_data, "–£—Ä–∞–ª–µ—Ü/Xingtai")
    with open(OUTPUT_SQL, 'w', encoding='utf-8') as f:
        f.write(sql_content)
    file_size = Path(OUTPUT_SQL).stat().st_size / 1024
    print(f"  ‚úì {OUTPUT_SQL}")
    print(f"  ‚úì –†–∞–∑–º–µ—Ä: {file_size:.1f} KB")
    print(f"  ‚úì INSERT statements: {inserted}\n")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    print("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
    categories = {}
    for product in merged_data:
        cat = product.get('category', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        categories[cat] = categories.get(cat, 0) + 1

    for cat, count in sorted(categories.items(), key=lambda x: -x[1])[:10]:
        print(f"  ‚Ä¢ {cat:30s} : {count:3d} —Ç–æ–≤–∞—Ä–æ–≤")

    print("\n" + "="*70)
    print("‚úÖ –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print("="*70)
    print(f"\nüìÅ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    print(f"  ‚Ä¢ JSON: {OUTPUT_JSON}")
    print(f"  ‚Ä¢ CSV:  {OUTPUT_CSV}")
    print(f"  ‚Ä¢ SQL:  {OUTPUT_SQL}")
    print(f"\nüìä –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {total}")
    print(f"  ‚Ä¢ –£—Ä–∞–ª–µ—Ü:  {len(uralets_data)}")
    print(f"  ‚Ä¢ Xingtai: {len(xingtai_data)}\n")

if __name__ == "__main__":
    main()
