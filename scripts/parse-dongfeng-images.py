#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤ DongFeng —Å —Å–∞–π—Ç–∞ dongfeng-traktor.com
"""

import asyncio
import json
import re
from pathlib import Path
from urllib.parse import urljoin, urlparse

import aiohttp
from playwright.async_api import async_playwright

# –ë–∞–∑–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
BASE_URL = "https://dongfeng-traktor.com/"
OUTPUT_DIR = Path(__file__).parent.parent / "parsed_data"
IMAGES_DIR = OUTPUT_DIR / "dongfeng_images"
MAPPING_FILE = OUTPUT_DIR / "dongfeng_image_mapping.json"

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
IMAGES_DIR.mkdir(exist_ok=True)

# –ú–æ–¥–µ–ª–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞
MODELS = [
    "244",
    "244 G2",
    "244G2",
    "304",
    "404",
    "504",
    "504 G3",
    "504G3",
    "704",
    "804",
    "904",
    "1004",
    "1204",
    "1304",
    "1304E",
    "1404",
    "1604",
    "2004",
]


async def download_image(session, url, filename):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ URL"""
    try:
        async with session.get(url, timeout=30) as response:
            if response.status == 200:
                filepath = IMAGES_DIR / filename
                content = await response.read()
                with open(filepath, "wb") as f:
                    f.write(content)
                print(f"  ‚úì –°–∫–∞—á–∞–Ω–æ: {filename}")
                return str(filepath)
    except Exception as e:
        print(f"  ‚úó –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è {filename}: {e}")
    return None


async def parse_images():
    """–ü–∞—Ä—Å–∏—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å —Å–∞–π—Ç–∞"""
    print("=" * 70)
    print("–ü–ê–†–°–ò–ù–ì –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô –¢–†–ê–ö–¢–û–†–û–í DONGFENG")
    print("=" * 70)

    async with async_playwright() as p:
        print("\nüöÄ –ó–∞–ø—É—Å–∫ –±—Ä–∞—É–∑–µ—Ä–∞...")
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()

        print(f"üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {BASE_URL}...")
        await page.goto(BASE_URL, wait_until="networkidle", timeout=60000)
        await page.wait_for_timeout(5000)  # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞

        print("\nüîç –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤...")

        # –ò—â–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        all_images = await page.query_selector_all("img")
        print(f"–ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {len(all_images)}")

        image_mapping = {}
        found_images = []

        for img in all_images:
            try:
                # –ü–æ–ª—É—á–∞–µ–º URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                src = await img.get_attribute("src")
                if not src:
                    src = await img.get_attribute("data-src")
                if not src:
                    continue

                # –î–µ–ª–∞–µ–º URL –∞–±—Å–æ–ª—é—Ç–Ω—ã–º
                if not src.startswith("http"):
                    src = urljoin(BASE_URL, src)

                # –ü–æ–ª—É—á–∞–µ–º alt —Ç–µ–∫—Å—Ç –∏ title
                alt = await img.get_attribute("alt") or ""
                title = await img.get_attribute("title") or ""

                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Ä—è–¥–æ–º —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
                parent = await img.evaluate_handle("el => el.parentElement")
                parent_text = (
                    await parent.evaluate("el => el.textContent") if parent else ""
                )

                combined_text = f"{alt} {title} {parent_text}".lower()

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫ DongFeng
                if (
                    "dongfeng" in combined_text
                    or "–¥–æ–Ω–≥—Ñ–µ–Ω–≥" in combined_text
                    or "–¥—Ñ" in combined_text
                ):
                    # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –º–æ–¥–µ–ª—å
                    for model in MODELS:
                        model_pattern = model.replace(" ", "\\s*")
                        if re.search(
                            rf"\b{model_pattern}\b", combined_text, re.IGNORECASE
                        ):
                            found_images.append(
                                {
                                    "model": model,
                                    "url": src,
                                    "alt": alt,
                                    "title": title,
                                }
                            )
                            print(f"  ‚úì –ù–∞–π–¥–µ–Ω–æ: DongFeng {model}")
                            break

            except Exception as e:
                continue

        print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –º–æ–¥–µ–ª–µ–π: {len(found_images)}")

        await browser.close()

        return found_images


async def download_all_images(images):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    print("\nüì• –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")

    image_mapping = {}

    async with aiohttp.ClientSession() as session:
        for i, img_data in enumerate(images):
            model = img_data["model"]
            url = img_data["url"]

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞
            ext = Path(urlparse(url).path).suffix or ".jpg"
            filename = f"dongfeng-{model.replace(' ', '-').lower()}{ext}"

            print(f"\nüì∑ DongFeng {model}")
            print(f"  URL: {url}")

            filepath = await download_image(session, url, filename)

            if filepath:
                image_mapping[model] = {
                    "filename": filename,
                    "filepath": filepath,
                    "url": url,
                    "alt": img_data.get("alt"),
                    "title": img_data.get("title"),
                }

    return image_mapping


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –ü–∞—Ä—Å–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    images = await parse_images()

    if not images:
        print("\n‚ö†Ô∏è  –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.")
        print("–ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤—Ä—É—á–Ω—É—é...")

        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ - –∏—â–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å DongFeng
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()

            await page.goto(BASE_URL, wait_until="networkidle")
            await page.wait_for_timeout(5000)

            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            all_images = await page.evaluate("""
                () => {
                    const images = [];
                    document.querySelectorAll('img').forEach(img => {
                        if (img.src && img.src.includes('http')) {
                            images.push({
                                src: img.src,
                                alt: img.alt || '',
                                title: img.title || '',
                                width: img.width,
                                height: img.height
                            });
                        }
                    });
                    return images;
                }
            """)

            await browser.close()

            # –§–∏–ª—å—Ç—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–±–æ–ª—å—à–∏–µ, –≤–µ—Ä–æ—è—Ç–Ω–æ —Ç—Ä–∞–∫—Ç–æ—Ä—ã)
            print(f"\nüìä –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(all_images)}")

            tractor_images = []
            for img in all_images:
                # –ë–µ—Ä–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–æ–ª—å—à–µ 200x200
                if img["width"] >= 200 and img["height"] >= 200:
                    # –ò—Å–∫–ª—é—á–∞–µ–º –ª–æ–≥–æ—Ç–∏–ø—ã –∏ –∏–∫–æ–Ω–∫–∏
                    if (
                        "logo" not in img["src"].lower()
                        and "icon" not in img["src"].lower()
                    ):
                        tractor_images.append(
                            {
                                "model": "unknown",
                                "url": img["src"],
                                "alt": img["alt"],
                                "title": img["title"],
                            }
                        )

            print(f"üñºÔ∏è  –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤: {len(tractor_images)}")

            if tractor_images:
                images = tractor_images[:20]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 20

    if not images:
        print("\n‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return

    # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    mapping = await download_all_images(images)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞–ø–ø–∏–Ω–≥
    with open(MAPPING_FILE, "w", encoding="utf-8") as f:
        json.dump(mapping, f, ensure_ascii=False, indent=2)

    print(f"\n‚úÖ –ú–∞–ø–ø–∏–Ω–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {MAPPING_FILE}")
    print(f"üìÅ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {IMAGES_DIR}")
    print(f"\nüìä –°–∫–∞—á–∞–Ω–æ: {len(mapping)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")


if __name__ == "__main__":
    asyncio.run(main())
