#!/usr/bin/env python3
"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä TATA-AGRO-MOTO.COM —Å –ü–û–õ–ù–´–ú–ò –¥–∞–Ω–Ω—ã–º–∏
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python3 parse-tata-agro-universal.py <URL> <output_filename>
"""

import sys
import requests
from bs4 import BeautifulSoup
import csv
import json
import time
import re
from pathlib import Path

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

def parse_page(url, page_num):
    """–ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É"""
    if page_num == 1:
        page_url = url
    else:
        separator = '&' if '?' in url else '?'
        page_url = f"{url}{separator}page={page_num}"

    try:
        response = requests.get(page_url, headers=HEADERS, timeout=30)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')

        products = []
        items = soup.select('.product-list > li')

        print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –Ω–∞–π–¥–µ–Ω–æ {len(items)} —Ç–æ–≤–∞—Ä–æ–≤")

        for item in items:
            try:
                # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –∏ URL
                link_elem = item.select_one('a[href]')
                title = ""
                product_url = link_elem.get('href', '') if link_elem else ""

                # –ù–∞–∑–≤–∞–Ω–∏–µ –≤ span –≤–Ω—É—Ç—Ä–∏ —Å—Å—ã–ª–∫–∏
                name_span = item.select_one('a span')
                if name_span:
                    title = name_span.text.strip()

                # –ê—Ä—Ç–∏–∫—É–ª –∏–∑ .prodcode (–≤–Ω—É—Ç—Ä–∏ –µ—Å—Ç—å span —Å –Ω–∞–ª–∏—á–∏–µ–º, –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å —Ç–æ–ª—å–∫–æ "–ö–æ–¥: XXXX")
                article_elem = item.select_one('.prodcode')
                article = ""
                if article_elem:
                    # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∏ –∏—â–µ–º "–ö–æ–¥: XXXX"
                    full_text = article_elem.get_text()
                    code_match = re.search(r'(?:–ö–æ–¥|–ê—Ä—Ç–∏–∫—É–ª|Code):\s*(\S+)', full_text, flags=re.IGNORECASE)
                    if code_match:
                        article = code_match.group(1).strip()

                # –¶–µ–Ω–∞ –∏–∑ .price__current
                price_elem = item.select_one('.price__current')
                price = ""
                if price_elem:
                    price_text = price_elem.text.strip()
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã
                    price_match = re.search(r'[\d\s]+\.?\d*', price_text.replace(' ', ''))
                    if price_match:
                        price = price_match.group(0).replace(' ', '')

                # –§–æ—Ç–æ
                image_elem = item.select_one('img')
                image_url = ""
                if image_elem:
                    image_url = image_elem.get('src', '') or image_elem.get('data-src', '')
                    # –ï—Å–ª–∏ URL –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π, –¥–µ–ª–∞–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–º
                    if image_url and not image_url.startswith('http'):
                        if image_url.startswith('//'):
                            image_url = 'https:' + image_url
                        else:
                            image_url = 'https://tata-agro-moto.com/' + image_url.lstrip('/')

                # –ù–∞–ª–∏—á–∏–µ
                stock_elem = item.select_one('.product-in-stock, .stock_status_id_7')
                stock = stock_elem.text.strip() if stock_elem else "–£—Ç–æ—á–Ω—è–π—Ç–µ"

                # –û–ø–∏—Å–∞–Ω–∏–µ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                description = ""

                # –ë—Ä–µ–Ω–¥ –∏–∑ URL
                brand = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
                url_lower = url.lower()
                if 'dongfeng' in url_lower:
                    brand = "DongFeng"
                elif 'foton' in url_lower:
                    brand = "Foton"
                elif 'jinma' in url_lower:
                    brand = "Jinma"
                elif 'xingtai' in url_lower:
                    brand = "Xingtai"
                elif 'shifeng' in url_lower:
                    brand = "Shifeng"
                elif 'zubr' in url_lower:
                    brand = "Zubr"

                products.append({
                    'title': title,
                    'article': article,
                    'price': price,
                    'brand': brand,
                    'category': '–ó–∞–ø—á–∞—Å—Ç–∏',
                    'stock': stock,
                    'description': description,
                    'url': product_url,
                    'image_url': image_url
                })

            except Exception as e:
                print(f"      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–≤–∞—Ä–∞: {e}")
                continue

        return products

    except Exception as e:
        print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
        return []

def main():
    if len(sys.argv) < 3:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python3 parse-tata-agro-universal.py <URL> <output_filename>")
        sys.exit(1)

    base_url = sys.argv[1]
    output_name = sys.argv[2]

    print(f"\nüöÄ –ü–ê–†–°–ò–ù–ì: {base_url}")
    print("=" * 70)

    # –ü–∞—Ä—Å–∏–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    all_products = []
    page = 1

    print("\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤...\n")

    while True:
        products = parse_page(base_url, page)

        if not products or len(products) == 0:
            break

        all_products.extend(products)
        page += 1
        time.sleep(0.5)

        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ 50 —Å—Ç—Ä–∞–Ω–∏—Ü
        if page > 50:
            print("   ‚ö†Ô∏è  –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü (50)")
            break

    print(f"\n‚úÖ –í—Å–µ–≥–æ —Å–ø–∞—Ä—Å–µ–Ω–æ: {len(all_products)} —Ç–æ–≤–∞—Ä–æ–≤")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    output_dir = Path("parsed_data/tata-agro")
    output_dir.mkdir(parents=True, exist_ok=True)

    csv_file = output_dir / f"{output_name}.csv"
    json_file = output_dir / f"{output_name}.json"

    # CSV
    fieldnames = ['title', 'article', 'price', 'brand', 'category', 'stock', 'description', 'url', 'image_url']
    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        if all_products:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(all_products)

    print(f"üíæ CSV: {csv_file}")

    # JSON
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(all_products, f, ensure_ascii=False, indent=2)

    print(f"üíæ JSON: {json_file}")
    print("‚úÖ –ì–æ—Ç–æ–≤–æ!\n")

if __name__ == "__main__":
    main()
