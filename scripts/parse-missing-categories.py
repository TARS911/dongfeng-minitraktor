#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–∞—Ä—Å–µ—Ä –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –ø—Ä–æ–ø—É—â–µ–Ω—ã
–ü–∞—Ä—Å–∏—Ç: Xingtai (412), JINMA (414) –∏ –¥—Ä—É–≥–∏–µ –≥–ª—É–±–æ–∫–∏–µ –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏
"""
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path
import requests
from bs4 import BeautifulSoup

sys.stdout.reconfigure(line_buffering=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
BASE_URL = "https://xn----7sbabpgpk4bsbesjp1f.xn--p1ai"
OUTPUT_DIR = Path(__file__).parent.parent / "parsed_data" / "agrodom"
OUTPUT_FILE = OUTPUT_DIR / "missing-categories.json"
LOG_FILE = OUTPUT_DIR / "missing-parse.log"

OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# HTTP —Å–µ—Å—Å–∏—è
session = requests.Session()
session.headers.update({
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
})

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
all_products = []
seen_product_links = set()

# –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
MISSING_CATEGORIES = [
    {
        "name": "Xingtai, –£—Ä–∞–ª–µ—Ü, Swatt –∏ –¥—Ä –æ—Ç 12-24 –ª.—Å",
        "url": f"{BASE_URL}/product-category/–∑–∞–ø—á–∞—Å—Ç–∏-–¥–ª—è-—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤/xingtai-—É—Ä–∞–ª–µ—Ü-swatt-–∏-–¥—Ä-–æ—Ç-12-24-–ª-—Å/",
        "expected": 412
    },
    {
        "name": "JINMA",
        "url": f"{BASE_URL}/product-category/–∑–∞–ø—á–∞—Å—Ç–∏-–¥–ª—è-—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤/jinma/",
        "expected": 414
    },
]


def log(message, level="INFO"):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_message = f"[{timestamp}] [{level}] {message}"
    print(log_message)
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(log_message + "\n")


def get_products_from_page(url, category_name, retry=3):
    """–ü–∞—Ä—Å–∏—Ç —Ç–æ–≤–∞—Ä—ã —Å –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    for attempt in range(retry):
        try:
            response = session.get(url, timeout=30)
            response.raise_for_status()
            soup = BeautifulSoup(response.content, "html.parser")

            products = []
            product_cards = soup.select(".product, .type-product")

            for item in product_cards:
                try:
                    # –ù–∞–∑–≤–∞–Ω–∏–µ
                    name_elem = item.select_one(
                        "h2, .product-title, .woocommerce-loop-product__title"
                    )
                    if not name_elem:
                        continue

                    name = name_elem.get_text(strip=True)

                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                    if "(" in name and ")" in name and name[-1] == ")":
                        continue

                    # –°—Å—ã–ª–∫–∞
                    link_elem = item.select_one("a")
                    if not link_elem:
                        continue

                    link = link_elem.get("href", "")

                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                    if link in seen_product_links:
                        continue

                    # –¶–µ–Ω–∞
                    price_elem = item.select_one(".price .amount, .woocommerce-Price-amount")
                    price = price_elem.get_text(strip=True) if price_elem else ""

                    # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    image_elem = item.select_one("img")
                    image_url = ""
                    if image_elem:
                        image_url = image_elem.get("src", "") or image_elem.get("data-src", "")

                    # SKU
                    sku_elem = item.select_one(".sku")
                    sku = sku_elem.get_text(strip=True) if sku_elem else ""

                    if name and link:
                        products.append({
                            "name": name,
                            "category": category_name,
                            "price": price,
                            "image_url": image_url,
                            "link": link,
                            "sku": sku,
                        })
                        seen_product_links.add(link)

                except Exception as e:
                    log(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–∞: {e}", "WARN")
                    continue

            return products

        except requests.RequestException as e:
            if attempt < retry - 1:
                log(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{retry} –Ω–µ —É–¥–∞–ª–∞—Å—å, –ø–æ–≤—Ç–æ—Ä...", "WARN")
                time.sleep(2 * (attempt + 1))
            else:
                log(f"–û—à–∏–±–∫–∞ –ø–æ—Å–ª–µ {retry} –ø–æ–ø—ã—Ç–æ–∫: {e}", "ERROR")
                return []

    return []


def parse_category(category):
    """–ü–∞—Ä—Å–∏—Ç –≤—Å–µ —Ç–æ–≤–∞—Ä—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Å–æ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü"""
    log(f"=" * 70)
    log(f"üì¶ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category['name']}")
    log(f"üîó URL: {category['url']}")
    log(f"üìä –û–∂–∏–¥–∞–µ—Ç—Å—è: {category['expected']} —Ç–æ–≤–∞—Ä–æ–≤")
    log(f"=" * 70)

    category_products = []

    for page_num in range(1, 101):  # –ú–∞–∫—Å–∏–º—É–º 100 —Å—Ç—Ä–∞–Ω–∏—Ü
        page_url = category['url'] if page_num == 1 else f"{category['url']}page/{page_num}/"

        log(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}...")
        products = get_products_from_page(page_url, category['name'])

        if not products:
            if page_num == 1:
                log(f"‚ö†Ô∏è  –¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ!", "WARN")
            break

        category_products.extend(products)
        log(f"  ‚úÖ –ü–æ–ª—É—á–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products)} (–≤—Å–µ–≥–æ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {len(category_products)})")

        time.sleep(0.5)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏

    log(f"")
    log(f"üí∞ –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {len(category_products)}")
    log(f"üìä –û–∂–∏–¥–∞–ª–æ—Å—å: {category['expected']}")

    if len(category_products) < category['expected']:
        diff = category['expected'] - len(category_products)
        log(f"‚ö†Ô∏è  –ù–µ–¥–æ—Å—Ç–∞–µ—Ç {diff} —Ç–æ–≤–∞—Ä–æ–≤!", "WARN")

    return category_products


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    log("=" * 70)
    log("üöÄ –ü–ê–†–°–ò–ù–ì –ü–†–û–ü–£–©–ï–ù–ù–´–• –ö–ê–¢–ï–ì–û–†–ò–ô")
    log("=" * 70)
    log("")

    start_time = time.time()

    for i, category in enumerate(MISSING_CATEGORIES, 1):
        log(f"")
        log(f"[{i}/{len(MISSING_CATEGORIES)}] –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏...")

        products = parse_category(category)
        all_products.extend(products)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
            json.dump(all_products, f, ensure_ascii=False, indent=2)

        log(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ. –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(all_products)}")
        log("")

        time.sleep(1)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏

    elapsed = time.time() - start_time

    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    log("=" * 70)
    log("üéâ –ü–ê–†–°–ò–ù–ì –ó–ê–í–ï–†–®–ï–ù!")
    log("=" * 70)
    log(f"‚úÖ –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(all_products)}")
    log(f"üìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {OUTPUT_FILE}")
    log(f"‚è±Ô∏è  –í—Ä–µ–º—è: {elapsed:.2f} —Å–µ–∫ ({elapsed/60:.2f} –º–∏–Ω)")
    log("=" * 70)


if __name__ == "__main__":
    main()
