#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import json
import os
import sys
import time
import requests
from bs4 import BeautifulSoup

sys.stdout.reconfigure(line_buffering=True)

BASE_URL = "https://xn----7sbabpgpk4bsbesjp1f.xn--p1ai"
OUTPUT_FILE = "parsed_data/agrodom/all-parts-recursive.json"

MAIN_CATEGORIES = [
    "–∑–∞–ø—á–∞—Å—Ç–∏-–¥–ª—è-—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤",
    "–∑–∞–ø—á–∞—Å—Ç–∏-–¥–ª—è-–Ω–∞–≤–µ—Å–Ω–æ–≥–æ-–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è",
    "–∑–∞–ø—á–∞—Å—Ç–∏-–¥–ª—è-–¥–∏–∑–µ–ª–µ–π",
    "—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ-–∏–∑–¥–µ–ª–∏—è",
    "–ø—Ä–æ—á–∏–µ-–∑–∞–ø—á–∞—Å—Ç–∏",
    "–≥–∏–¥—Ä–∞–≤–ª–∏–∫–∞",
    "–∫–∞—Ä–¥–∞–Ω–Ω—ã–µ-–≤–∞–ª—ã",
    "–∫–æ–ª—ë—Å–∞-—à–∏–Ω—ã-–≥—Ä—É–∑–∞",
    "—Ñ–∏–ª—å—Ç—Ä–∞",
    "–¥–≤–∏–≥–∞—Ç–µ–ª—è-–¥–∏–∑–µ–ª—å–Ω—ã–µ",
    "—Å—Ç–∞—Ä—Ç–µ—Ä—ã-–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã",
    "—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ-–∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏–µ",
    "—Å–∏–¥–µ–Ω—å—è-–∫—Ä–µ—Å–ª–∞",
    "–∑–∏–ø",
    "–æ–∂–∏–¥–∞–µ—Ç—Å—è",
]

session = requests.Session()
session.headers.update({"User-Agent": "Mozilla/5.0"})
visited_urls = set()

def get_subcategories(url):
    try:
        response = session.get(url, timeout=20)
        soup = BeautifulSoup(response.content, "html.parser")
        subcats = []
        for link in soup.select('.product-categories a, .product-category a'):
            href = link.get('href')
            if href and 'product-category' in href and href not in visited_urls:
                subcats.append(href)
        return subcats
    except:
        return []

def get_products_from_page(url):
    try:
        response = session.get(url, timeout=20)
        soup = BeautifulSoup(response.content, "html.parser")
        products = []
        for item in soup.select(".product, .type-product"):
            name_elem = item.select_one("h2, .product-title, .woocommerce-loop-product__title")
            if not name_elem:
                continue
            name = name_elem.get_text(strip=True)
            if "(" in name and ")" in name and name[-1] == ")":
                continue
            link = item.select_one("a")
            price = item.select_one(".price .amount, .woocommerce-Price-amount")
            image = item.select_one("img")
            if name and link:
                products.append({
                    "name": name,
                    "price": price.get_text(strip=True) if price else "",
                    "image_url": image.get("src", "") if image else "",
                    "link": link.get("href", ""),
                })
        return products
    except:
        return []

def parse_category_recursive(url, depth=0):
    if url in visited_urls or depth > 2:
        return []
    visited_urls.add(url)
    indent = "  " * depth
    print(f"{indent}–ü–∞—Ä—Å–∏–Ω–≥: {url.split('/')[-2]}")
    
    all_products = []
    
    # –ü–∞—Ä—Å–∏–º —Ç–æ–≤–∞—Ä—ã —Å —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π
    for page in range(1, 100):
        page_url = url if page == 1 else f"{url}page/{page}/"
        products = get_products_from_page(page_url)
        if not products:
            break
        all_products.extend(products)
        time.sleep(0.3)
    
    if all_products:
        print(f"{indent}  –¢–æ–≤–∞—Ä–æ–≤: {len(all_products)}")
    
    # –ò—â–µ–º –ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    subcats = get_subcategories(url)
    if subcats:
        print(f"{indent}  –ü–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏–π: {len(subcats)}")
        for subcat_url in subcats:
            sub_products = parse_category_recursive(subcat_url, depth + 1)
            all_products.extend(sub_products)
            time.sleep(0.3)
    
    return all_products

def main():
    os.makedirs("parsed_data/agrodom", exist_ok=True)
    print("\n–†–ï–ö–£–†–°–ò–í–ù–´–ô –ü–ê–†–°–ò–ù–ì –í–°–ï–• –ó–ê–ü–ß–ê–°–¢–ï–ô")
    print("=" * 70)
    
    all_products = []
    seen_names = set()
    
    for i, cat_slug in enumerate(MAIN_CATEGORIES, 1):
        print(f"\n[{i}/{len(MAIN_CATEGORIES)}] {cat_slug}")
        url = f"{BASE_URL}/product-category/{cat_slug}/"
        
        try:
            products = parse_category_recursive(url)
            new_count = 0
            for p in products:
                name_key = p["name"].lower().strip()
                if name_key not in seen_names:
                    seen_names.add(name_key)
                    all_products.append(p)
                    new_count += 1
            
            print(f"  –ù–æ–≤—ã—Ö: {new_count}, –í—Å–µ–≥–æ: {len(all_products)}")
            
            with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
                json.dump(all_products, f, ensure_ascii=False, indent=2)
            
            if i % 3 == 0:
                print(f"üíæ –ü—Ä–æ–≥—Ä–µ—Å—Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω")
        except Exception as e:
            print(f"  –û—à–∏–±–∫–∞: {e}")
    
    print(f"\n{'='*70}")
    print(f"–ó–ê–í–ï–†–®–ï–ù–û: {len(all_products)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤")
    print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {OUTPUT_FILE}")
    print(f"{'='*70}\n")

if __name__ == "__main__":
    main()
